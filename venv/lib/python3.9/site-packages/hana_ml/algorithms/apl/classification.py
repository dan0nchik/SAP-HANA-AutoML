# pylint:disable=too-many-lines
"""
This module provides the SAP HANA APL binary classification algorithm.

The following classes are available:

    * :class:`AutoClassifier`
"""
from collections import OrderedDict
import logging
import pandas as pd
from hdbcli import dbapi
from hana_ml.dataframe import (
    DataFrame)
from hana_ml.ml_base import execute_logged
from hana_ml.dataframe import quotename
from hana_ml.ml_exceptions import FitIncompleteError
from hana_ml.algorithms.apl.robust_regression_base import RobustRegressionBase

logger = logging.getLogger(__name__) #pylint: disable=invalid-name


class AutoClassifier(RobustRegressionBase):
    """
    SAP HANA APL Binary Classifier algorithm.

    Parameters
    ----------
    conn_context :  ConnectionContext, optional
        The connection object to an SAP HANA database.
        This parameter is not needed anymore.
        It will be set automatically when a dataset is used in fit() or predict().
    variable_auto_selection : bool, optional
        When set to True, variable auto-selection is activated.
        Variable auto-selection enables to maintain the performance of a model
        while keeping the lowest number of variables.
    polynomial_degree : int, optional
        The polynomial degree of the model. Default is 1.
    variable_storages: dict, optional
        Specifies the variable data types (string, integer, number).
        For example, {'VAR1': 'string', 'VAR2': 'number'}.
        See notes below for more details.
    variable_value_types: dict, optional
        Specifies the variable value type (continuous, nominal, ordinal).
        For example, {'VAR1': 'continuous', 'VAR2': 'nominal'}.
        See notes below for more details.
    variable_missing_strings: dict, optional
        Specifies the variable values that will be taken as missing.
        For example, {'VAR1': '???'} means anytime the variable value equals to '???',
        it will be taken as missing.
    extra_applyout_settings: dict optional
        Defines other outputs the model should generate in addition to the predicted values.
        For example: {'APL/ApplyReasonCode':'3;Mean;Below;False'}
        will add reason codes in the output when the model is applied.
        These reason codes provide explanation about the prediction.
        See *OPERATION_CONFIG parameters* in *APPLY_MODEL function*, `SAP HANA APL Reference Guide
        <https://help.sap.com/viewer/p/apl>`_.
    other_params: dict optional
        Corresponds to advanced settings.
        The dictionary contains {<parameter_name>: <parameter_value>}.
        The possible parameters are:
            - 'correlations_lower_bound'
            - 'correlations_max_kept'
            - 'cutting_strategy'
            - 'exclude_low_predictive_confidence'
            - 'risk_fitting'
            - 'risk_fitting_min_cumulated_frequency'
            - 'risk_fitting_nb_pdo'
            - 'risk_fitting_use_weights'
            - 'risk_gdo'
            - 'risk_mode'
            - 'risk_pdo'
            - 'risk_score'
            - 'score_bins_count'
            - 'target_key'
            - 'variable_selection_best_iteration'
            - 'variable_selection_min_nb_of_final_variables'
            - 'variable_selection_max_nb_of_final_variables'
            - 'variable_selection_mode'
            - 'variable_selection_nb_variables_removed_by_step'
            - 'variable_selection_percentage_of_contribution_kept_by_step'
            - 'variable_selection_quality_bar'
            - 'variable_selection_quality_criteria'
        See *Common APL Aliases for Model Training* in the `SAP HANA APL Reference Guide
        <https://help.sap.com/viewer/p/apl>`_.
    other_train_apl_aliases: dict, optional
        Users can provide APL aliases as advanced settings to the model.
        Unlike 'other_params' described above, users are free to input any possible value.
        There is no control in python.

    Attributes
    ----------
    model_ : hana_ml DataFrame
        The trained model content
    summary_ : APLArtifactTable
        The reference to the "SUMMARY" table generated by the model training.
        This table contains the content of the model training summary.
    indicators_ : APLArtifactTable
        The reference to the "INDICATORS" table generated by the model training.
        This table contains various metrics related to model and model variables.
    fit_operation_logs_: APLArtifactTable
        The reference to the "OPERATION_LOG" table generated by the model training
    var_desc_ : APLArtifactTable
        The reference to the "VARIABLE_DESCRIPTION" table that was built during the model training
    applyout_ : hana_ml DataFrame
        The predictions generated the last time the model was applied
    predict_operation_logs_: APLArtifactTable
        The reference to the "OPERATION_LOG" table when a prediction was made

    Examples
    --------
    >>> from hana_ml.algorithms.apl.classification import AutoClassifier
    >>> from hana_ml.dataframe import ConnectionContext, DataFrame

    Connecting to SAP HANA

    >>> CONN = ConnectionContext(HDB_HOST, HDB_PORT, HDB_USER, HDB_PASS)
    >>> # -- Creates hana_ml DataFrame
    >>> hana_df = DataFrame(CONN, 'select * from APL_SAMPLES.CENSUS')

    Creating and fitting the model

    >>> model = AutoClassifier(variable_auto_selection=True)
    >>> model.fit(hana_df, label='class', key='id')

    Making the predictions

    >>> apply_out = model.predict(hana_df)
    >>> print(apply_out.head(3).collect())
        id  TRUE_LABEL  PREDICTED  PROBABILITY
    0   30           0          0     0.688153
    1   63           0          0     0.677693
    2   66           0          0     0.700221

    Adding individual contributions to the output of predictions

    >>> model.set_params(
    ...    extra_applyout_settings={
    ...        'APL/ApplyContribution': 'all'
    ...        })
    >>> apply_out = model.predict(hana_df)
    >>> print(apply_out.head(3).collect())
        id  TRUE_LABEL  PREDICTED  PROBABILITY  contrib_age_rr_class ...
    0   30           0          0     0.688153              0.043387 ...
    1   63           0          0     0.677693              0.042608 ...
    2   66           0          0     0.700221              0.020784 ...

    Adding reason codes to the output of predictions

    >>> model.set_params(
    ...    extra_applyout_settings={
    ...        'APL/ApplyReasonCode':'3;Mean;Below;False'
    ...        })
    >>> apply_out = model.predict(hana_df)
    >>> print(apply_out.head(3).collect())
       id  TRUE_LABEL  PREDICTED  PROBABILITY RCN_B_Mean_1_rr_class ...
    0  30           0          0     0.688153         education-num ...
    1  63           0          0     0.677693         education-num ...
    2  66           0          0     0.700221         education-num ...

    Debriefing

    >>> model.get_performance_metrics()
    OrderedDict([('L1', 0.2522171212463023), ('L2', 0.32254434028379236), ...

    >>> model.get_feature_importances()
    OrderedDict([('marital-status', 0.2172766583204266), ('capital-gain', 0.19521247617062215),...

    Saving the model in the schema named 'MODEL_STORAGE'.
    Please see model_storage class for further features of model storage.

    >>> from hana_ml.model_storage import ModelStorage
    >>> model_storage = ModelStorage(connection_context=CONN, schema='MODEL_STORAGE')
    >>> model.name = 'My classification model name'
    >>> model_storage.save_model(model=model, if_exists='replace')

    Notes
    -----
        It is highly recommended to use a dataset with a key provided in the fit() method.
        If not, once the model is trained, it will not be possible anymore to
        use the predict() method with a key, because the model will not expect it.

        By default, when it is not given, SAP HANA APL guesses the variable description by reading
        the first 100 rows. But, sometimes, it does not provide the correct result.
        By specifically providing values in these parameters, the user can overwrite the default
        guess. For example:
        ::
            model.set_params(
                    variable_storages = {
                        'ID': 'integer',
                        'sepal length (cm)': 'number'
                        })
            model.set_params(
                    variable_value_types = {
                        'sepal length (cm)': 'continuous'
                        })
            model.set_params(
                    variable_missing_strings = {
                        'sepal length (cm)': '-1'
                        })
            model.set_params(
                extra_applyout_settings={
                        'APL/ApplyReasonCode':'3;Mean;Below;False'
                        })
    """

    def __init__(self,
                 conn_context=None,
                 variable_auto_selection=True,
                 polynomial_degree=None,
                 variable_storages=None,
                 variable_value_types=None,
                 variable_missing_strings=None,
                 extra_applyout_settings=None,
                 ** other_params): #pylint: disable=too-many-arguments
        super(AutoClassifier, self).__init__(
            conn_context,
            variable_auto_selection,
            polynomial_degree,
            variable_storages,
            variable_value_types,
            variable_missing_strings,
            extra_applyout_settings,
            ** other_params)
        # For classification, the target variable must be nominal
        self._force_target_var_type = 'nominal'

    # pylint: disable=too-many-arguments
    def fit(self, data,
            key=None,
            features=None,
            label=None,
            weight=None):
        """
        Fits the model.

        Parameters
        ----------
        data : DataFrame
            The training dataset
        key : str, optional
            The name of the ID column.
            This column will not be used as feature in the model.
            It will be output as row-id when prediction is made with the model.
            If `key` is not provided, an internal key is created. But this is not recommended
            usage. See notes below.
        features : list of str, optional
            The names of the features to be used in the model.
            If `features` is not provided, all non-ID and non-label columns will be taken.
        label : str, optional
            The name of the label column. Default is the last column.
        weight : str, optional
            The name of the weight variable.
            A weight variable allows one to assign a relative weight to each of the observations.

        Returns
        -------
        self : object

        Notes
        -----
        It is highly recommended to use a dataset with key in the fit() method.
        If not, once the model is trained, it will not be possible anymore to
        use the predict() method with a dataset with key, because the model will not expect it.
        """
        if label is None:
            label = data.columns[-1]
        return self._fit(data=data,
                         key=key,
                         features=features,
                         label=label,
                         weight=weight)

    def _rewrite_applyout_df(self, data, applyout_df):
        """
        Rewrites the applyout dataframe so it outputs standardized column names.
        """
        # Find the name of the label column in applyout table (rr_XXXX)
        label_name = self._get_target_varname_from_applyout_table(
            applyout_df=applyout_df,
            target_varname=None
            )
        mapping = OrderedDict()
        mapping['?'] = '@FIRST_COL'  # whatever first column - key column
        mapping[label_name] = 'TRUE_LABEL'
        mapping['decision_rr_' + label_name] = 'PREDICTED'
        mapping['proba_decision_rr_' + label_name] = 'PROBABILITY'
        mapping['rr_' + label_name] = '@HIDE'
        # 'rr_' + label_name: 'SCORING_VALUE'  # hidden

        sql = 'SELECT '
        i = 0
        # ---- maps columns
        applyout_table_columns = applyout_df.columns
        mapped_cols = []  # cols that are mapped
        for old_col in mapping.keys():
            new_col = mapping[old_col]
            if new_col == '@HIDE':
                mapped_cols.append(old_col)
                continue
            if new_col == '@FIRST_COL':
                # key column
                new_col = applyout_table_columns[0]
                old_col = new_col
                mapped_cols.append(old_col)
            # TRUE_LABEL has to be ignored if it is not given as input
            if new_col == 'TRUE_LABEL':
                if old_col not in data.columns:
                    continue
            if old_col not in applyout_table_columns:
                raise Exception(
                    'Cannot find column {old_col} from the output'.format(
                        old_col=old_col))
            if i > 0:
                sql = sql + ', '
            sql = (sql + '{old_col} {new_col}'.format(
                old_col=quotename(old_col),
                new_col=quotename(new_col)))
            mapped_cols.append(old_col)
            i = i + 1

        # add extra columns for which we can't map (reason_code for example)
        for i, out_col in enumerate(applyout_df.columns):
            if out_col not in mapped_cols \
                    and out_col != label_name:  # label might be ignored it was not in apply-in
                sql = sql + ', '
                sql = (sql + '{ex_col} '.format(ex_col=quotename(out_col)))

        sql = sql + ' FROM ' + self.applyout_table_.name
        applyout_df_new = DataFrame(connection_context=self.conn_context,
                                    select_statement=sql)
        # logger.info('DataFrame for predict ouput: ' + sql)
        return applyout_df_new

    def predict(self, data):
        """
        Makes predictions with the fitted model.
        It is possible to add special outputs, such as reason codes, by specifying
        extra_applyout_setting parameter in the model.
        This parameter is explained above in the model class section.

        Parameters
        ----------
        data : hana_ml DataFrame
            The dataset used for prediction

        Returns
        -------
        Prediction output: hana_ml DataFrame
        The dataframe contains the following columns:
        - KEY : the key column if it was provided in the dataset
        - TRUE_LABEL : the class label when it was given in the dataset
        - PREDICTED : the predicted label
        - PROBABILITY : the probability of the predicted label to be correct (confidence)
        - SCORING_VALUE : the unnormalized scoring value

        """
        # APPLY_CONFIG
        # default config
        apply_config_data_df = pd.DataFrame([
            ('APL/ApplyExtraMode', 'Advanced Apply Settings', None),
            ('APL/ApplyDecision', 'true', None),
            ('APL/ApplyProbaDecision', 'true', None)])
        if self.extra_applyout_settings is not None:
            # add extra options given by user
            for k in self.extra_applyout_settings:
                apply_config_data_df = apply_config_data_df.append(
                    [[k, self.extra_applyout_settings[k], None]])
        applyout_df = self._predict(data=data,
                                    apply_config_data_df=apply_config_data_df)
        return self._rewrite_applyout_df(data=data,
                                         applyout_df=applyout_df)

    def score(self, data):
        """
        Returns the mean accuracy on the provided test dataset.

        Parameters
        ----------
        data : hana_ml DataFrame
            The test dataset used to compute the score.
            The labels must be provided in the dataset.

        Returns
        -------
            mean average accuracy: float
        """

        applyout_df = self.predict(data)

        # Find the name of the label column in applyout table
        true_label_col = 'TRUE_LABEL'
        pred_label_col = 'PREDICTED'

        # Check if the label column is given in input dataset (true label)
        # If it is not present, score can't be calculated
        if true_label_col not in applyout_df.columns:
            raise FitIncompleteError("Cannot find true label column in dataset")
        try:
            with self.conn_context.connection.cursor() as cur:
                # Count TP + TN
                sql = ('SELECT COUNT(*) FROM ({APPLYOUT_DF}) '
                       + 'WHERE "{true_label_col}"="{pred_label_col}"')
                sql = sql.format(APPLYOUT_DF=applyout_df.select_statement,
                                 true_label_col=true_label_col,
                                 pred_label_col=pred_label_col)
                execute_logged(cur, sql)
                ret = cur.fetchone()
                return ret[0]/float(data.count())  # (TP + TN)/ Total
        except dbapi.Error as db_er:
            logger.error(
                "Failed to calculate the score, the error message: %s",
                db_er,
                exc_info=True)
            raise
